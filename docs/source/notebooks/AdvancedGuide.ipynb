{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Guide to `caskade`\n",
    "\n",
    "The beginners guide layed out the basics of constructing simulators in `caskade`, now we will present the powerful capabilities and techniques that let you easily and efficiently perform complex analyses. The order of these techniques has no particular meaning, so you may search for points of interest or scan through for relevant sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import caskade as ckd\n",
    "from time import time, sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "class Gaussian(ckd.Module):\n",
    "    def __init__(self, name, x0=None, y0=None, q=None, phi=None, sigma=None, I0=None):\n",
    "        super().__init__(name)\n",
    "        self.x0 = ckd.Param(\"x0\", x0) # position\n",
    "        self.y0 = ckd.Param(\"y0\", y0)\n",
    "        self.q = ckd.Param(\"q\", q) # axis ratio\n",
    "        self.phi = ckd.Param(\"phi\", phi) # orientation\n",
    "        self.sigma = ckd.Param(\"sigma\", sigma) # width\n",
    "        self.I0 = ckd.Param(\"I0\", I0) # intensity\n",
    "\n",
    "    @ckd.forward\n",
    "    def _r(self, x, y, x0=None, y0=None, q=None, phi=None):\n",
    "        x, y = x - x0, y - y0\n",
    "        s, c = torch.sin(phi), torch.cos(phi)\n",
    "        x, y = c * x - s * y, s * x + c * y\n",
    "        return (x ** 2 + (y * q) ** 2).sqrt()\n",
    "    \n",
    "    @ckd.forward\n",
    "    def brightness(self, x, y, sigma=None, I0=None):\n",
    "        return I0 * (-self._r(x, y)**2 / sigma**2).exp()\n",
    "    \n",
    "class Combined(ckd.Module):\n",
    "    def __init__(self, name, first, second, ratio=0.5):\n",
    "        super().__init__(name)\n",
    "        self.first = first # Modules are automatically registered\n",
    "        self.ratio = ckd.Param(\"ratio\", ratio, valid=(0,1))\n",
    "        self.second = second\n",
    "\n",
    "    @ckd.forward\n",
    "    def brightness(self, x, y, ratio):\n",
    "        return ratio * self.first.brightness(x, y) + (1 - ratio) * self.second.brightness(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways of accessing Param values\n",
    "\n",
    "When running a simulation there are several ways to access the value of a `Param` object, here is a mostly complete listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TryParam(ckd.Module):\n",
    "    def __init__(self, submod):\n",
    "        super().__init__()\n",
    "        self.x = ckd.Param(\"x\", 1.0)\n",
    "        self.y = ckd.Param(\"y\", 2.0)\n",
    "        self.submod = submod\n",
    "\n",
    "    @ckd.forward\n",
    "    def test_access(self, a, x, k=1, y=None):\n",
    "        # Regular function attribute, is not a caskade object and so behaves normally\n",
    "        total = a\n",
    "        total += k\n",
    "\n",
    "        # Getting values from Param objects\n",
    "        total += x ** 2 # as arg of function (preferred)\n",
    "        total += y ** 2 # as kwarg of function (preferred)\n",
    "        total += self.x.value ** 2 # by attribute (allowed but discouraged)\n",
    "        total += self.submod.I0.value ** 2 # by attribute of submod (allowed but may indicate inefficient code)\n",
    "\n",
    "        # Modifying values of Param objects\n",
    "        x = 3.0 # locally modify param value (allowed)\n",
    "        total += x ** 2 # use modified value, will not change the param value globally\n",
    "        total += self.submod.brightness(0,0, sigma=2.0) # call module with modified param value, only affects this call (allowed)\n",
    "        self.x.value = 4.0 # modify param value globally (explicitly forbidden)\n",
    "        return total\n",
    "    \n",
    "G = Gaussian(\"G\", x0=5, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0)\n",
    "T = TryParam(G)\n",
    "\n",
    "try:\n",
    "    T.test_access(0.0)\n",
    "except ckd.ActiveStateError as e:\n",
    "    print(\"Caught ActiveStateError:\", e)\n",
    "\n",
    "# Outside a @forward function, we can still access param values like so:\n",
    "print(\"x:\", T.x.value)\n",
    "# If a Param is a pointer, and you access the `value` it will try to evaluate the pointer\n",
    "G.sigma = T.x\n",
    "print(\"sigma:\", G.sigma.value) # Basic pointer to another Param\n",
    "G.sigma = lambda p: p.x.value * 2.0\n",
    "G.sigma.link(T.x)\n",
    "print(\"sigma:\", G.sigma.value) # Function pointer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control dynamic vs static param\n",
    "\n",
    "One of the most powerful features of `caskade` is its flexible system for switching which parameters are dynamic (involved in sampling/fitting) and which are static (fixed). This allows a single simulator object to perform many tasks with a uniform interface. Here we will see a few options for controlling this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All params initialized with a value\n",
    "G1 = Gaussian(\"G1\", x0=5, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0)\n",
    "G2 = Gaussian(\"G2\", x0=5, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0)\n",
    "C = Combined(\"C\", G1, G2)\n",
    "print(\"All params are static automatically when given a value\")\n",
    "display(C.graphviz())\n",
    "\n",
    "# Set individual param to dynamic\n",
    "G1.x0.to_dynamic() # call function to set dynamic\n",
    "G1.q = None # set to None to make dynamic\n",
    "C.to_dynamic() # only sets immediate children to dynamic\n",
    "print(\"Individual params can be set to dynamic\")\n",
    "display(C.graphviz())\n",
    "\n",
    "# Set all simulator params to be dynamic\n",
    "C.to_dynamic(local_only=False)\n",
    "print(\"All params for the entire simulator may be set to dynamic\")\n",
    "display(C.graphviz())\n",
    "\n",
    "# Even when set to dynamic, the params remember their original values\n",
    "print(\"x0:\", G1.x0.value)\n",
    "G1.x0 = G1.x0.value # Setting value sets to static\n",
    "G1.q.to_static() # Setting to static, uses the earlier value\n",
    "\n",
    "# Setting any value will make it static\n",
    "G1.I0 = 10.0 \n",
    "print(\"Individual params can be set to static\")\n",
    "display(C.graphviz())\n",
    "\n",
    "# Similarly a whole simulator can be set static\n",
    "C.to_static(local_only=False)\n",
    "print(\"All params for the entire simulator may be set to static\")\n",
    "display(C.graphviz())\n",
    "\n",
    "# Use a param list to set multiple params to dynamic\n",
    "paramset1 = ckd.NodeList([G1.x0, G1.q, G2.phi, G2.sigma])\n",
    "paramset1.to_dynamic() # set all params in the list to dynamic\n",
    "print(\"Use a NodeList to curate which params are set to dynamic/static\")\n",
    "display(C.graphviz())\n",
    "\n",
    "# NOTE: trying to set a dynamic param to static when there is no stored value will throw an error\n",
    "badparam = ckd.Param(\"badparam\")\n",
    "print(\"Blank param is dynamic: \", badparam.dynamic)\n",
    "try:\n",
    "    badparam.to_static()\n",
    "except Exception as e:\n",
    "    print(f\"Caught error: {type(e)}: {e}\")\n",
    "    print(\"Param is still dynamic: \", badparam.dynamic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call function with internally modified param value\n",
    "\n",
    "A caskade simulator often is build of nested modules that call each others functions. Sometimes one may wish to call a function but with a different value for one of the Params than what has been given in the input (for example when computing a reference for comparison). Here we will show how to do this kind of local Param modification. This is also covered in [Ways of accessing Param values](#ways-of-accessing-param-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TryModify(ckd.Module):\n",
    "    def __init__(self, submod):\n",
    "        super().__init__()\n",
    "        self.submod = submod\n",
    "        self.newval1 = torch.tensor(2.0)\n",
    "        self.newval2 = torch.tensor(3.0)\n",
    "\n",
    "    @ckd.forward\n",
    "    def test_modify(self):\n",
    "        init = self.submod.brightness(0,0) # call with original param values\n",
    "        mod = self.submod.brightness(0,0, sigma=self.newval1) # call with modified param value\n",
    "        with ckd.OverrideParam(self.submod.sigma, self.newval2):\n",
    "            othermod = self.submod.brightness(0,0) # call with temporarily modified param value\n",
    "        assert init != mod\n",
    "        assert init != othermod\n",
    "        assert mod != othermod\n",
    "        print(\"See, they are all different!\")\n",
    "        return init, mod, othermod\n",
    "    \n",
    "G = Gaussian(\"G\", x0=5, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0)\n",
    "T = TryModify(G)\n",
    "print(T.test_modify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparametrize a Module\n",
    "\n",
    "Sometimes it makes sense to write a module and its functions using a particular parametrization, but on some occasions or for user interpretation it should be given in another parametrization. For example, it may be easier to write some model in cartesian coordinates, but for users the polar coordinates are easier to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Gaussian(\"G\", x0=5, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0) # default in cartesian coordinates\n",
    "r = ckd.Param(\"r\", 1.0) # radius\n",
    "theta = ckd.Param(\"theta\", 0.0) # angle\n",
    "G.x0 = lambda p: p.r.value * torch.cos(p.theta.value)\n",
    "G.x0.link(r)\n",
    "G.x0.link(theta)\n",
    "G.y0 = lambda p: p.r.value * torch.sin(p.theta.value)\n",
    "G.y0.link(r)\n",
    "G.y0.link(theta)\n",
    "\n",
    "G.graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save, Append, and Load the Param values\n",
    "\n",
    "It is possible to save the state of the params in a `caskade` simulator in an HDF5 file. Once saved, one can append to the file to create a \"chain\" such as in MCMC sampling.\n",
    "\n",
    "Note: it is also possible to store meta data in the hdf5 file. Simply add the metadata in the `.meta` attribute of any of the `caskade` nodes and it will be stored at the appropriate place in the graph. See the [Add meta data](#add-meta-data-to-a-param-or-module) section for how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the gaussian in polar coordinates example\n",
    "G = Gaussian(\"G\", x0=5, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0)\n",
    "r = ckd.Param(\"r\", 1.0)\n",
    "theta = ckd.Param(\"theta\", 0.0)\n",
    "G.x0 = lambda p: p.r.value * torch.cos(p.theta.value)\n",
    "G.x0.link(r)\n",
    "G.x0.link(theta)\n",
    "G.y0 = lambda p: p.r.value * torch.sin(p.theta.value)\n",
    "G.y0.link(r)\n",
    "G.y0.link(theta)\n",
    "\n",
    "# Run the \"MCMC\"\n",
    "G.save_state(\"gauss_chain.h5\", appendable=True) # save the initial state\n",
    "\n",
    "# Pretend to run a sampling chain\n",
    "for _ in range(100):\n",
    "    G.x0.value += np.random.normal(0.01, 0.1)\n",
    "    G.y0.value += np.random.normal(0.01, 0.1)\n",
    "    G.q.value = np.clip(G.q.value + 0.1 * np.random.randn(), 0.1, 0.9)\n",
    "    G.phi.value = (G.phi.value + 0.1 * np.random.randn()) % np.pi\n",
    "    G.sigma.value += np.random.normal(0.1, 0.05)\n",
    "    G.I0.value += np.random.normal(0.01, 0.5)\n",
    "\n",
    "    G.append_state(\"gauss_chain.h5\") # append the new state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Now we can read the chain back in\n",
    "fig, axarr = plt.subplots(6, 6, figsize=(12, 12))\n",
    "with h5py.File(\"gauss_chain.h5\", \"r\") as f: # Load the hdf5 file directly\n",
    "    for i, ikey in enumerate([\"x0\", \"y0\", \"q\", \"phi\", \"sigma\", \"I0\"]):\n",
    "        idata = f[\"G\"][ikey][\"value\"] # access values for a given param\n",
    "        for j, jkey in enumerate([\"x0\", \"y0\", \"q\", \"phi\", \"sigma\", \"I0\"]):\n",
    "            jdata = f[\"G\"][jkey][\"value\"] # access values for a given param\n",
    "            if i < j:\n",
    "                axarr[i,j].axis(\"off\")\n",
    "                continue\n",
    "            elif i == j:\n",
    "                axarr[i, j].hist(idata, bins=50, color=\"k\")\n",
    "                axarr[i, j].set_xlabel(ikey)\n",
    "                axarr[i, j].set_ylabel(\"Counts\")\n",
    "            else:\n",
    "                axarr[i, j].scatter(jdata, idata, s=2, color=\"k\")\n",
    "            axarr[i, j].set_xlabel(jkey)\n",
    "            axarr[i, j].set_ylabel(ikey)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also simply load the state of a module from the hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.load_state(\"gauss_chain.h5\", 32) # Load the 32nd state from the chain\n",
    "\n",
    "print(\"Loaded state 32:\")\n",
    "print(f\"x0: {G.x0.value.item():.2f}\") \n",
    "print(f\"y0: {G.y0.value.item():.2f}\")\n",
    "print(f\"q: {G.q.value.item():.2f}\")\n",
    "print(f\"phi: {G.phi.value.item():.2f}\")\n",
    "print(f\"sigma: {G.sigma.value.item():.2f}\")\n",
    "print(f\"I0: {G.I0.value.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add meta data to a Param or Module\n",
    "\n",
    "Sometimes it is very useful to carry along some extra data right next to your params. For example, you may want to keep track of the uncertainty of a param value. The best way to do this is by tacking on attributes to the `meta` container in a `Param`. This is essentially an empty class which you may then build on however you like. Anything you do to this object is guaranteed not to interfere with `caskade` stuff. Similarly, making attributes with the `meta_` prefix is guaranteed not to interfere with `caskade` stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ckd.Param(\"p\", 1.0) \n",
    "\n",
    "p.meta.extra_info = 42 # add attribute to meta container (preferred)\n",
    "p.meta_extra_info = 42 # add attribute with \"meta_\" prefix (allowed)\n",
    "p.extra_info = 42 # add attribute directly to Param object (allowed but discouraged due to potential conflicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to define new types of `Param` objects by subclassing `Param`, however one should be careful not to make differences too extreme if they wish to interact with other `caskade` based packages. A straightforward example would be when making a package where every parameter will store an uncertainty, rather than creating the attribute for each new `Param`, one can just make a class that starts with it from the outset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamU(ckd.Param):\n",
    "    def __init__(self, *args, uncertainty = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if uncertainty is None:\n",
    "            self.uncertainty = torch.zeros_like(self.value)\n",
    "        else:\n",
    "            self.uncertainty = uncertainty\n",
    "\n",
    "p = ParamU(\"p\", 1.0)\n",
    "print(f\"p: {p.value} +- {p.uncertainty}\")\n",
    "p2 = ParamU(\"p2\", 2.0, uncertainty=0.1)\n",
    "print(f\"p2: {p2.value} +- {p2.uncertainty}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break up a Param Tensor\n",
    "\n",
    "Sometimes a `Param` value is naturally a multi-component tensor, but we only wish for part of it to be dynamic. This can be accomplished by creating new params and linking appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the param we plan to use\n",
    "x = ckd.Param(\"x\", torch.arange(10)) # param has 10 elements\n",
    "print(\"Original x tensor\", x.value)\n",
    "\n",
    "# These are sub params for the broken primary param\n",
    "x_dynamic = ckd.Param(\"x_dynamic\", torch.arange(3)) # want first three elements to be dynamic\n",
    "x_dynamic.to_dynamic()\n",
    "x_static = ckd.Param(\"x_static\", torch.arange(3,10)) # want last seven elements to be static\n",
    "\n",
    "# This rebuilds the full param from the broken params\n",
    "x.value = lambda p: torch.cat((p.x_dynamic.value, p.x_static.value))\n",
    "x.link(x_dynamic)\n",
    "x.link(x_static)\n",
    "\n",
    "# Here we see we get the same result, but now only the first three elements are dynamic!\n",
    "print(\"Rebuilt x tensor\", x.value)\n",
    "x.graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching with caskade\n",
    "\n",
    "Adding batch dimensions allows for more efficient computation by requiring less communication between the CPU and GPU, or simply by letting the CPU spend more time doing computations and less time reading python code. In `caskade` it is possible to fully take advantage of batching capabilities of ones code. Here we demo the basic format for doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1, vmap\n",
    "\n",
    "`vmap` is a utility in PyTorch that lets you automatically add a batch dimension to your inputs and outputs. You can think of it like a faster version of a `for-loop` that just stacks all the outputs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Gaussian(\"G\", x0=5, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0)\n",
    "G.sigma.to_dynamic()\n",
    "G.phi.to_dynamic()\n",
    "x, y = torch.meshgrid(torch.linspace(0,10,100), torch.linspace(0,10,100), indexing=\"ij\")\n",
    "\n",
    "# Batching using vmap                phi                            sigma\n",
    "params = torch.stack((torch.linspace(0.0, 3.14/2, 5), torch.linspace(0.5, 4.0, 5)), dim=-1)\n",
    "img = torch.vmap(G.brightness, in_dims=(None, None, 0), out_dims=0)(x, y, params)\n",
    "fig, axarr = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, ax in enumerate(axarr):\n",
    "    ax.imshow(img[i].detach().numpy(), origin=\"lower\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Multiple batching with vmap\n",
    "# imagine the brightness function could only take a single value, rather than a grid\n",
    "#                                            batch x y                        batch params\n",
    "img = torch.vmap(torch.vmap(G.brightness, in_dims=(0,0,None)), in_dims=(None, None, 0))(x.flatten(), y.flatten(), params)\n",
    "img = img.reshape(5, *x.shape)\n",
    "fig, axarr = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, ax in enumerate(axarr):\n",
    "    ax.imshow(img[i].detach().numpy(), origin=\"lower\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2, Module with batch dimension\n",
    "\n",
    "If you write a module assuming the user will pass parameters with a batch dimension, then you can handle direct batching without using wrappers like `vmap`. This requires a bit more care in managing the shapes of each object, but can pay off a lot in terms of speed and flexibility later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBatched(ckd.Module):\n",
    "    def __init__(self, name, x0=None, y0=None, q=None, phi=None, sigma=None, I0=None):\n",
    "        super().__init__(name)\n",
    "        self.x0 = ckd.Param(\"x0\", x0) # position\n",
    "        self.y0 = ckd.Param(\"y0\", y0)\n",
    "        self.q = ckd.Param(\"q\", q) # axis ratio\n",
    "        self.phi = ckd.Param(\"phi\", phi) # orientation\n",
    "        self.sigma = ckd.Param(\"sigma\", sigma) # width\n",
    "        self.I0 = ckd.Param(\"I0\", I0) # intensity\n",
    "\n",
    "    @ckd.forward\n",
    "    def _r(self, x, y, x0=None, y0=None, q=None, phi=None):\n",
    "        x0 = x0.unsqueeze(-1)\n",
    "        y0 = y0.unsqueeze(-1)\n",
    "        q = q.unsqueeze(-1)\n",
    "        phi = phi.unsqueeze(-1)\n",
    "        x, y = x - x0, y - y0\n",
    "        s, c = torch.sin(phi), torch.cos(phi)\n",
    "        x, y = c * x - s * y, s * x + c * y\n",
    "        return (x ** 2 + (y * q) ** 2).sqrt()\n",
    "    \n",
    "    @ckd.forward\n",
    "    def brightness(self, x, y, sigma=None, I0=None):\n",
    "        init_shape = x.shape\n",
    "        B, *_ = sigma.shape\n",
    "        x = x.flatten()\n",
    "        y = y.flatten()\n",
    "        return (I0.unsqueeze(-1) * (-self._r(x, y)**2 / sigma.unsqueeze(-1)**2).exp()).reshape(B, *init_shape)\n",
    "    \n",
    "G = GaussianBatched(\"G\", x0=[5], y0=[5], q=[0.5], phi=[0.0], sigma=[1.0], I0=[1.0])\n",
    "G.to_dynamic() # all params are dynamic\n",
    "x, y = torch.meshgrid(torch.linspace(0,10,100), torch.linspace(0,10,100), indexing=\"ij\")\n",
    "\n",
    "# Batching on all dims using batched tensor input\n",
    "params = G.build_params_array()\n",
    "params = params.repeat(5, 1) # 5 copies of the same params\n",
    "params[:,3] = torch.linspace(0.0, 3.14/2, 5) # phi\n",
    "params[:,4] = torch.linspace(0.5, 4.0, 5) # sigma\n",
    "img = G.brightness(x, y, params=params)\n",
    "fig, axarr = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, ax in enumerate(axarr):\n",
    "    ax.imshow(img[i].detach().numpy(), origin=\"lower\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Batching by setting shapes of params, then flat tensor input\n",
    "for param in G.dynamic_params:\n",
    "    param.shape = (5,) + param.shape # add batch dimension to shape\n",
    "params = params.T.flatten() # now params is a flat tensor again\n",
    "img = G.brightness(x, y, params=params)\n",
    "fig, axarr = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, ax in enumerate(axarr):\n",
    "    ax.imshow(img[i].detach().numpy(), origin=\"lower\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Batching using list input, note that list allows for different shapes, (also true for dictionary params)\n",
    "params = [\n",
    "    torch.tensor(5), # x0\n",
    "    torch.tensor(5), # y0\n",
    "    torch.tensor(0.5), # q\n",
    "    torch.linspace(0.0, 3.14/2, 5), # phi, batched\n",
    "    torch.linspace(0.5, 4.0, 5), # sigma, batched\n",
    "    torch.tensor(1.0) # I0\n",
    "]\n",
    "img = G.brightness(x, y, params=params)\n",
    "fig, axarr = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, ax in enumerate(axarr):\n",
    "    ax.imshow(img[i].detach().numpy(), origin=\"lower\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Param from a Module\n",
    "\n",
    "It is possible to remove a Param object from a module and later replace it. This may be helpful for getting a simulator exactly the way you want it. You may use this to have multiple modules share a Param rather than just pointing to the same object. Generally, this is not preferred practice since it is just as fast to use pointers and they are more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = Gaussian(\"G1\", x0=None, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0)\n",
    "G2 = Gaussian(\"G2\", x0=5, y0=5, q=0.5, phi=0.0, sigma=1.0, I0=1.0)\n",
    "C = Combined(\"C\", G1, G2)\n",
    "\n",
    "del G2.x0 # remove a param from a module\n",
    "\n",
    "C.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.x0 = G1.x0 # assign a param from one module to another\n",
    "C.graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointer functions only called once\n",
    "\n",
    "When you create a pointer function it may be arbitrarily complex, which may require a lot of compute. To maintain efficiency, the pointer is only called once for a given simulation then the value is stored. This shouldn't matter on the user side, but it is just good to know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TryCallPointer(ckd.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = ckd.Param(\"x\", 1.0)\n",
    "        self.y = ckd.Param(\"y\", 2.0)\n",
    "\n",
    "    @ckd.forward\n",
    "    def test_call(self):\n",
    "        total = 0.0\n",
    "        start = time()\n",
    "        total += self.x.value\n",
    "        print(f\"first call took {time()-start:.5f} sec\")\n",
    "        start = time()\n",
    "        total += self.x.value\n",
    "        print(f\"second call took {time()-start:.5f} sec\")\n",
    "        return total\n",
    "    \n",
    "def long_function(p):\n",
    "    sleep(2)\n",
    "    return 1.0 + p.y.value\n",
    "\n",
    "T = TryCallPointer()\n",
    "T.x = long_function\n",
    "T.x.link(T.y)\n",
    "print(T.test_call())\n",
    "\n",
    "print(\"\\nOutside @forward the pointer is called every time:\")\n",
    "start = time()\n",
    "T.x.value\n",
    "print(f\"first outside call took {time()-start:.5f} sec\")\n",
    "start = time()\n",
    "T.x.value\n",
    "print(f\"second outside call took {time()-start:.5f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
