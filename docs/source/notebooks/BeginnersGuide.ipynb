{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginners Guide to `caskade`\n",
    "\n",
    "Here we will introduce all of the relevant concepts and capabilities of `caskade` and how to build numerical simulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caskade as ck\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Template\n",
    "\n",
    "All `caskade` simulators follow the same basic template. Certain ingredients are always involved:\n",
    "\n",
    "- Subclass the `Module` object\n",
    "- Call the `super().__init__(name)` at the top\n",
    "- Create some `Param` attributes\n",
    "- Decorate a function(s) with `@forward`\n",
    "- use the params (by name) in the decorated function(s)\n",
    "\n",
    "You can also provide a name for the `Module`, though this is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(ck.Module):\n",
    "    def __init__(self, name, x0=None, q=None, phi=None, sigma=None, I0=None):\n",
    "        super().__init__(name)\n",
    "        self.x0 = ck.Param(\"x0\", x0, shape=(2,)) # position\n",
    "        self.q = ck.Param(\"q\", q) # axis ratio\n",
    "        self.phi = ck.Param(\"phi\", phi) # orientation\n",
    "        self.sigma = ck.Param(\"sigma\", sigma) # width\n",
    "        self.I0 = ck.Param(\"I0\", I0) # intensity\n",
    "\n",
    "    @ck.forward\n",
    "    def _r(self, x, y, x0=None, q=None, phi=None):\n",
    "        x, y = x - x0[...,0], y - x0[...,1]\n",
    "        s, c = torch.sin(phi), torch.cos(phi)\n",
    "        x, y = c * x - s * y, s * x + c * y\n",
    "        return (x ** 2 + (y * q) ** 2).sqrt()\n",
    "    \n",
    "    @ck.forward\n",
    "    def brightness(self, x, y, sigma=None, I0=None):\n",
    "        return I0 * (-self._r(x, y)**2 / sigma**2).exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now create instances of this simulator, and inspect what the compute graph looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstsim = Gaussian(\"my first module\", sigma = 0.2, I0 = 1.0)\n",
    "print(firstsim) # print the graph\n",
    "firstsim.graphviz() # show the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best practice is to initialize the simulator with initial values for all params (or provide values shortly after creating the simulator as part of initialization).\n",
    "\n",
    "Use the `to_dynamic` and `to_static` to control the status of each param or module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondsim = Gaussian(\"my second module\", x0=(0,0), q=0.5, phi=3.14/3, sigma=0.2, I0=1.0)\n",
    "x, y = torch.meshgrid(torch.linspace(-1, 1, 100), torch.linspace(-1, 1, 100), indexing=\"ij\")\n",
    "secondsim.to_dynamic() # all params owned by secondsim are now dynamic\n",
    "secondsim.sigma.to_static() # sigma is now static\n",
    "secondsim.I0.to_static() # I0 is now static\n",
    "params = secondsim.build_params_array() # automatically build a tensor for the dynamic params\n",
    "plt.imshow(secondsim.brightness(x, y, params), origin=\"lower\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "secondsim.graphviz() # show the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ways to pass the parameters\n",
    "\n",
    "W can pass the parameters into a `caskade` forward method as one of a `list`, a 1D `Tensor`, or a `dict`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# List of tensors\n",
    "params_list = secondsim.build_params_list()\n",
    "print(\"Params list:\", params_list)\n",
    "ax[0].imshow(secondsim.brightness(x, y, params_list), origin=\"lower\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"List of tensors\")\n",
    "\n",
    "# Single flattened tensor\n",
    "params_tensor = secondsim.build_params_array()\n",
    "print(\"Params tensor:\", params_tensor)\n",
    "ax[1].imshow(secondsim.brightness(x, y, params_tensor), origin=\"lower\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"Single flattened tensor\")\n",
    "\n",
    "# Dictionary of tensors, using attribute names of either Param or Module objects\n",
    "params_dict = secondsim.build_params_dict()\n",
    "print(\"Params dict:\", params_dict)\n",
    "ax[2].imshow(secondsim.brightness(x, y, params_dict), origin=\"lower\")\n",
    "ax[2].axis(\"off\")\n",
    "ax[2].set_title(\"Dictionary of tensors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, once we have the `params` we can either pass it as the last positional argument, as a `params=` keyword, or we can set them as `static`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Pass as last positional argument\n",
    "ax[0].imshow(secondsim.brightness(x, y, params_list), origin=\"lower\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Last positional argument\")\n",
    "\n",
    "# Pass as keyword argument\n",
    "ax[1].imshow(secondsim.brightness(x, y, params=params_list), origin=\"lower\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"Keyword argument\")\n",
    "\n",
    "# Set parameters as static\n",
    "secondsim.to_static()\n",
    "ax[2].imshow(secondsim.brightness(x, y), origin=\"lower\")\n",
    "ax[2].axis(\"off\")\n",
    "ax[2].set_title(\"Static parameters\")\n",
    "# Set them back to dynamic by setting them to None (works the same as `to_dynamic`)\n",
    "secondsim.x0 = None\n",
    "secondsim.q = None\n",
    "secondsim.phi = None\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `pointer` parameter\n",
    "\n",
    "So far we have only looked at `dynamic` and `static` parameters. `caskade` allows users to build complex simulators with relationships between parameters. Next lets see the `pointer` type: \n",
    "\n",
    "- `dynamic` is given as input when calling a `@forward` method\n",
    "- `static` is a fixed value\n",
    "- `pointer` returns the value computed from other nodes in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirdsim = Gaussian(\"my third module\", phi = 3.14*5/6, q = 0.2, sigma = 0.2, I0 = 0.5)\n",
    "thirdsim.x0 = secondsim.x0 # now they share the same position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirdsim.graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a `pointer` parameter is represented in the graph as a shaded arrow. It will now return the same value as the `x0` parameter in `secondsim`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Modules\n",
    "\n",
    "The real power of `caskade` comes from nesting `Module` objects to build complex scientific simulators, all while keeping the flexible and robust interfaces seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combined(ck.Module):\n",
    "    def __init__(self, name, first, second):\n",
    "        super().__init__(name)\n",
    "        self.first = first # Modules are automatically registered\n",
    "        self.second = second\n",
    "\n",
    "    @ck.forward\n",
    "    def brightness(self, x, y):\n",
    "        return self.first.brightness(x, y) + self.second.brightness(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedsim = Combined(\"my combined module\", secondsim, thirdsim)\n",
    "print(combinedsim)\n",
    "combinedsim.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same params as before since secondsim is all static or pointers to firstsim\n",
    "plt.imshow(combinedsim.brightness(x, y, params_list), origin=\"lower\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Combined brightness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional `pointer`s\n",
    "\n",
    "A `pointer` parameter determines it's value from other parameters. This can go beyond just returning the same value. One can define an arbitrary function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simtime = ck.Param(\"time\") # create a parameter for time\n",
    "secondsim.x0 = lambda p: (-p.time.value +0.5)*torch.tensor((1,-1))\n",
    "secondsim.x0.link(simtime)\n",
    "thirdsim.x0 = lambda p: p.time.value*torch.tensor((1,1)) - 0.5\n",
    "thirdsim.x0.link(simtime)\n",
    "\n",
    "secondsim.q = 0.5\n",
    "secondsim.phi = 3.14 / 3\n",
    "\n",
    "combinedsim.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "B = 64\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(combinedsim.brightness(x, y, torch.tensor([0.0])), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "ax.set_title(\"Brightness at time 0\")\n",
    "\n",
    "def update(i):\n",
    "    img.set_data(combinedsim.brightness(x, y, torch.tensor([i / B])))\n",
    "    ax.set_title(f\"Brightness at time {i / B:.2f}\")\n",
    "    return img\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=B, interval=60)\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Or display the animation inline\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with PyTorch\n",
    "\n",
    "The above animation was made with a `for-loop`, but using the `PyTorch` `vmap` function we can produce the frames a lot faster. In this case, `vmap` is up to 5x faster than the `for-loop` but with lots of fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_params_tensor = torch.linspace(0, 1, 64).reshape(64, 1) # only 1 param \"time\" so last dim is 1\n",
    "\n",
    "start = time()\n",
    "result = []\n",
    "for i in range(B):\n",
    "    result.append(combinedsim.brightness(x, y, batched_params_tensor[i]))\n",
    "result = torch.stack(result)\n",
    "print(\"for-loop time taken: \", time() - start)\n",
    "\n",
    "vbrightness = torch.vmap(combinedsim.brightness, in_dims=(None, None, 0))\n",
    "start = time()\n",
    "result = vbrightness(x, y, batched_params_tensor)\n",
    "print(\"vmap time taken: \", time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(8, 8, figsize=(8, 8))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(result[i], origin=\"lower\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `PyTorch` autograd functionalities on `caskade` simulators. All of the `PyTorch` calculus operations will work on `caskade` simulators, so one may compute a likelihood and perform gradient descent very easily, to name one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PyTorch autograd\n",
    "params_tensor = torch.tensor([0.5])\n",
    "plt.imshow(torch.func.jacfwd(combinedsim.brightness,argnums=2)(x, y, params_tensor), origin=\"lower\", cmap=\"seismic\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"gradient of brightness at t=0.5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `caskade` with numpy, jax, or general python objects\n",
    "\n",
    "It is possible to use `caskade` with other array like types like numpy and jax. You'll need to set the backend for `caskade` to run things properly. Ideally you should set the environment variable `CASKADE_BACKEND` and then `caskade` will run everything with your desired backend. The options are `torch`, `numpy`, `jax`, and `object`. The `object` option is a bit special, it will not be able to take advantage of array operations (such as constructing the flattened array input) but other options should work (i.e. a list of objects, one for each param). If you have a linux system running bash you can do:\n",
    "```bash\n",
    "export CASKADE_BACKEND=\"numpy\"\n",
    "```\n",
    "to switch over to run everything with numpy, and similar commands for any other backend option. The default is `torch` since that's what `caskade` was originally developed in. You can also change the backend on the fly like below, just note that this is a bit dangerous since you can have objects running around with different types. Ideally, you would set the backend at the top of your script and leave it as the same value throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy backend\n",
    "ck.backend.backend = \"numpy\"\n",
    "p = ck.Param(\"p\", 1.0)\n",
    "print(\"with numpy backend, p type:\", type(p.value))\n",
    "\n",
    "# jax backend\n",
    "ck.backend.backend = \"jax\"\n",
    "p = ck.Param(\"p\", 1.0)\n",
    "print(\"with jax backend, p type:\", type(p.value))\n",
    "\n",
    "# object backend\n",
    "ck.backend.backend = \"object\"\n",
    "p = ck.Param(\"p\", 1.0)\n",
    "print(\"with object backend, p type:\", type(p.value))\n",
    "\n",
    "# torch backend\n",
    "ck.backend.backend = \"torch\"\n",
    "p = ck.Param(\"p\", 1.0)\n",
    "print(\"with torch backend, p type:\", type(p.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done! Those are all the elemental abilities of `caskade`, I hope that by this point you have a sense of the vast possibilities of simulators that can be constructed. This is only the tip of the iceberg for `caskade`, check out the advanced tutorial for much more information about constructing simulators!\n",
    "\n",
    "\n",
    "Happy science-ing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
