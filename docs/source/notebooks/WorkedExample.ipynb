{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b44e33",
   "metadata": {},
   "source": [
    "# Example Usage (SN Light-Curve)\n",
    "\n",
    "Here we will work through an example to show the power of `caskade` in simplifying the process of developing an analysis routine. We will use a mock highly simplified supernova light curve fitting problem as our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caskade as ck\n",
    "import torch\n",
    "from torch.autograd.functional import hessian, jacobian\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357e549",
   "metadata": {},
   "source": [
    "Below we define our Gaussian and Combined modules like before. Expand to see the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d15e01",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "class Gaussian(ck.Module):\n",
    "    def __init__(self, name, x0=None, y0=None, q=None, phi=None, sigma=None, flux=None):\n",
    "        super().__init__(name)\n",
    "        self.x0 = ck.Param(\"x0\", x0) # position\n",
    "        self.y0 = ck.Param(\"y0\", y0)\n",
    "        self.q = ck.Param(\"q\", q) # axis ratio\n",
    "        self.phi = ck.Param(\"phi\", phi) # orientation\n",
    "        self.sigma = ck.Param(\"sigma\", sigma) # width\n",
    "        self.flux = ck.Param(\"flux\", flux) # total light\n",
    "\n",
    "    @ck.forward\n",
    "    def _r(self, x, y, x0=None, y0=None, q=None, phi=None):\n",
    "        x, y = x - x0, y - y0\n",
    "        s, c = torch.sin(phi), torch.cos(phi)\n",
    "        x, y = c * x - s * y, s * x + c * y\n",
    "        return (x ** 2 + (y * q) ** 2).sqrt()\n",
    "    \n",
    "    @ck.forward\n",
    "    def brightness(self, x, y, sigma=None, flux=None):\n",
    "        return flux * (-self._r(x, y)**2 / sigma**2).exp() / (2 * torch.pi * sigma**2).sqrt()\n",
    "    \n",
    "class Gaussian1D(ck.Module):\n",
    "    def __init__(self, name, t0=None, sigma=None, peak_flux=None):\n",
    "        super().__init__(name)\n",
    "        self.t0 = ck.Param(\"t0\", t0) # position\n",
    "        self.sigma = ck.Param(\"sigma\", sigma) # width\n",
    "        self.peak_flux = ck.Param(\"peak_flux\", peak_flux) # intensity\n",
    "\n",
    "    @ck.forward\n",
    "    def flux(self, t, peak_flux, t0, sigma):\n",
    "        return peak_flux * (-((t + t0) / sigma)**2).exp()\n",
    "    \n",
    "class Combined(ck.Module):\n",
    "    def __init__(self, name, x, y, models):\n",
    "        super().__init__(name)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.models = models \n",
    "\n",
    "    @ck.forward\n",
    "    def __call__(self):\n",
    "        return sum(model.brightness(self.x, self.y) for model in self.models)\n",
    "    \n",
    "class Noiser(ck.Module):\n",
    "    def __init__(self, name, model, read_noise=0.1, exp_time = 100):\n",
    "        super().__init__(name)\n",
    "        self.model = model\n",
    "        self.read_noise = read_noise\n",
    "        self.exp_time = exp_time\n",
    "\n",
    "    @ck.forward\n",
    "    def __call__(self):\n",
    "        img = self.model()\n",
    "        read_noise = torch.randn_like(img) * self.read_noise\n",
    "        poisson_noise = torch.randn_like(img) * (img*self.exp_time).sqrt() / self.exp_time\n",
    "        return img + read_noise + poisson_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a511ca",
   "metadata": {},
   "source": [
    "## Making the mock data\n",
    "\n",
    "This has to be done first since that is what we will analyze, however you should skip this section and come back to it after you've read the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nobs = 5\n",
    "imgsize = 50\n",
    "sigma_read = 0.1\n",
    "exp_time = 25\n",
    "imgx, imgy = torch.meshgrid(torch.linspace(-1,1, imgsize), torch.linspace(-1,1, imgsize), indexing='ij')\n",
    "SN = Gaussian(\"SN\", x0=-0.35, y0=-0.2, q=1.0, phi=0.0, sigma=0.05)\n",
    "SN_lightcurve = Gaussian1D(\"lightcurve\", t0=-3.0, sigma=2., peak_flux=0.25)\n",
    "time = ck.Param(\"time\")\n",
    "SN.flux = lambda p: p.lightcurve.flux(p.time.value)\n",
    "SN.flux.link((SN_lightcurve, time))\n",
    "Galaxy = Gaussian(\"Galaxy\", x0=0.2, y0=0.2, q=0.6, phi=0.5, sigma=0.3, flux=1.0)\n",
    "sim = Combined(\"sim\", imgx, imgy, [SN, Galaxy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91da26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 64\n",
    "fig, ax = plt.subplots()\n",
    "times = torch.linspace(0, 6, B)\n",
    "img = ax.imshow(sim([times[0]]), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "ax.set_title(\"Brightness at time 0\")\n",
    "\n",
    "def update(i):\n",
    "    img.set_data(sim([times[i]]).detach().numpy())\n",
    "    ax.set_title(f\"Brightness at time {times[i]:.2f}\")\n",
    "    return img\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=B, interval=60)\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Or display the animation inline\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a7a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = torch.linspace(0,6,Nobs)\n",
    "data = torch.zeros((Nobs, imgsize, imgsize))\n",
    "true_LC = SN_lightcurve.flux(times).detach().numpy()\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "noise_sim = Noiser(\"noise_sim\", sim, read_noise=sigma_read, exp_time= exp_time)\n",
    "fig, axarr = plt.subplots(1, 5, figsize=(15, 3))\n",
    "fig.suptitle(\"Mock Observations\")\n",
    "for i, t in enumerate(times):\n",
    "    data[i] = noise_sim([t])\n",
    "    axarr[i].imshow(data[i].detach().numpy(), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "    axarr[i].set_title(f\"t={t:.2f}\")\n",
    "    axarr[i].set_xlabel(\"X\")\n",
    "    axarr[i].set_ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5215be",
   "metadata": {},
   "source": [
    "## Analysis starting point: Model each image individually\n",
    "\n",
    "Let's imagine we are new to this problem and just starting out. We will make things simple and just analyze each image individually to construct our light curve. We are going to assume throughout that you know things like the read noise of your detector and the exposure time (which we are using as a basic noise model).\n",
    "\n",
    "We will perform a straightforward likelihood analysis, thus our main goal will be to construct a likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfaf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood(ck.Module):\n",
    "    def __init__(self, name, model, data, sigma_read=0.05, exp_time=25):\n",
    "        super().__init__(name)\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.sigma_read = sigma_read\n",
    "        self.exp_time = exp_time\n",
    "        \n",
    "    @ck.forward\n",
    "    def residuals(self):\n",
    "        model_output = self.model()\n",
    "        variance = self.sigma_read**2 + model_output / self.exp_time \n",
    "        sigma = variance.sqrt()\n",
    "        residuals = (self.data - model_output) / sigma\n",
    "        return residuals, sigma\n",
    "\n",
    "    @ck.forward\n",
    "    def __call__(self):\n",
    "        residuals, sigma = self.residuals()\n",
    "        return -0.5 * (residuals ** 2).sum() - sigma.log().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "SNmodel = Gaussian(\"SN\", x0=-0.35, y0=-0.2, q=1.0, phi=0.0, sigma=0.05, flux=0.2)\n",
    "SNmodel.x0.to_dynamic() # \"unknown\" parameters\n",
    "SNmodel.y0.to_dynamic()\n",
    "SNmodel.flux.to_dynamic()\n",
    "Galaxymodel = Gaussian(\"Galaxy\", x0=0.2, y0=0.2, q=0.6, phi=0.5, sigma=0.3, flux=1.0)\n",
    "Galaxymodel.to_dynamic() # \"unknown\" parameters\n",
    "firstmodel = Combined(\"firstmodel\", imgx, imgy, [SNmodel, Galaxymodel])\n",
    "likelihood = Likelihood(\"likelihood\", firstmodel, data[0], sigma_read=sigma_read, exp_time=exp_time)\n",
    "likelihood.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_curve_flux = []\n",
    "light_curve_sigma = []\n",
    "fig, axarr = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(\"Fit Model and Residuals\")\n",
    "for i in range(Nobs):\n",
    "    print(f\"Analyze time {times[i]:.2f}\")\n",
    "    likelihood.data = data[i]  # Update the data for each observation\n",
    "    x0 = likelihood.build_params_array()\n",
    "    x0 += torch.randn_like(x0) * 0.05  # Add some noise to the initial guess since we cant start at the true values\n",
    "    res = minimize(lambda x: -likelihood(torch.tensor(x)).numpy(), x0, method='Nelder-Mead')\n",
    "    light_curve_flux.append(res.x[2])\n",
    "    hess = hessian(likelihood, torch.tensor(res.x), strict=True)\n",
    "    hess_inv = torch.linalg.inv(hess)  # Invert the Hessian to get the covariance matrix\n",
    "    light_curve_sigma.append(hess_inv[2,2].abs().sqrt().item())  # Extract the uncertainty from the Hessian\n",
    "    axarr[0][i].imshow(firstmodel(torch.tensor(res.x)).detach().numpy(), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "    axarr[0][i].set_title(f\"t={times[i]:.2f}\")\n",
    "    axarr[0][i].axis(\"off\")\n",
    "    axarr[1][i].imshow(likelihood.residuals(torch.tensor(res.x))[0].detach().numpy(), origin=\"lower\", vmin=-3, vmax=3)\n",
    "    axarr[1][i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(times.numpy(), light_curve_flux, yerr=light_curve_sigma, fmt='o', label='Estimated flux')\n",
    "plt.plot(times.numpy(), true_LC, 'o', label='True flux')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('SN flux')\n",
    "plt.ylim(0,None)\n",
    "plt.title('Estimated SN flux over time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45fa18d",
   "metadata": {},
   "source": [
    "This is our first go at measuring the light curve. It mostly looks like what we should expect, the bright points are fit well but the faint ones fail and we get no meaningful flux estimate from them. For the very faint SN images, it is hard to see in the noise where the SN even is, let alone determine its flux. So next lets see if we can add some complexity to our model and get better results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b35d2",
   "metadata": {},
   "source": [
    "## Analysis Improvement: Joint modelling\n",
    "\n",
    "We don't need to analyze each image individually, we have some knowledge of how these SN should look in our data. For example, the position of the SN and galaxy should be constant with time, further, the galaxy should really be fixed over time, the only thing that changes is the SN flux, so lets encode that in our analysis.\n",
    "\n",
    "`caksade` lets us fix parameters to match each other, so we will make a model for each image then link the parameters accordingly to the first image model. This way our parameter vector will only include what's needed to model the full set of images. We also create a wrapper module to stack the results from all the models so it can easily be passed to the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgmodels = []\n",
    "for i in range(Nobs):\n",
    "    SNmodel = Gaussian(f\"SN{i}\", x0=-0.35, y0=-0.2, q=1.0, phi=0.0, sigma=0.05, flux=0.2) # we start from true parameters for demo simplicity\n",
    "    SNmodel.x0.to_dynamic() # \"unknown\" parameters\n",
    "    SNmodel.y0.to_dynamic()\n",
    "    SNmodel.flux.to_dynamic()\n",
    "    Galaxymodel = Gaussian(f\"Galaxy{i}\", x0=0.2, y0=0.2, q=0.6, phi=0.5, sigma=0.3, flux=1.0)\n",
    "    Galaxymodel.to_dynamic() # \"unknown\" parameters\n",
    "    imgmodel = Combined(f\"image{i}\", imgx, imgy, [SNmodel, Galaxymodel])\n",
    "    imgmodels.append(imgmodel)\n",
    "    if i > 0: # Shared parameters across images\n",
    "        SNmodel.x0 = imgmodels[0].models[0].x0\n",
    "        SNmodel.y0 = imgmodels[0].models[0].y0\n",
    "        Galaxymodel.x0 = imgmodels[0].models[1].x0\n",
    "        Galaxymodel.y0 = imgmodels[0].models[1].y0\n",
    "        Galaxymodel.q = imgmodels[0].models[1].q\n",
    "        Galaxymodel.phi = imgmodels[0].models[1].phi\n",
    "        Galaxymodel.sigma = imgmodels[0].models[1].sigma\n",
    "        Galaxymodel.flux = imgmodels[0].models[1].flux\n",
    "class Stack(ck.Module):\n",
    "    def __init__(self, name, models):\n",
    "        super().__init__(name)\n",
    "        self.models = models\n",
    "\n",
    "    @ck.forward\n",
    "    def __call__(self):\n",
    "        return torch.stack([model() for model in self.models], dim=0)\n",
    "secondmodel = Stack(\"secondmodel\", imgmodels)\n",
    "likelihood2 = Likelihood(\"likelihood2\", secondmodel, data, sigma_read=sigma_read, exp_time=exp_time)\n",
    "likelihood2.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit light curve\n",
    "x0 = likelihood2.build_params_array()\n",
    "x0 += torch.randn_like(x0) * 0.05  # Add some noise to the initial guess since we cant start at the true values\n",
    "res = minimize(lambda x: -likelihood2(torch.tensor(x)).numpy(), x0, method='Nelder-Mead')\n",
    "fig, axarr = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(\"Fit Model and Residuals (Joint Model)\")\n",
    "model_imgs = secondmodel(torch.tensor(res.x))\n",
    "residuals = likelihood2.residuals(torch.tensor(res.x))[0]\n",
    "for i in range(Nobs):\n",
    "    axarr[0][i].imshow(model_imgs[i].detach().numpy(), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "    axarr[0][i].set_title(f\"t={times[i]:.2f}\")\n",
    "    axarr[0][i].axis(\"off\")\n",
    "    axarr[1][i].imshow(residuals[i].detach().numpy(), origin=\"lower\", vmin=-3, vmax=3)\n",
    "    axarr[1][i].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# extract light curve\n",
    "likelihood2.fill_dynamic_values(torch.tensor(res.x))\n",
    "likelihood2.to_static(False)\n",
    "light_curve_flux = []\n",
    "light_curve_sigma = []\n",
    "for model in secondmodel.models:\n",
    "    light_curve_flux.append(model.models[0].flux.value.item())\n",
    "    model.models[0].flux.to_dynamic()\n",
    "hess = hessian(likelihood2, likelihood2.build_params_array(), strict=True)\n",
    "hess_inv = torch.linalg.inv(hess)  # Invert the Hessian to get the covariance matrix\n",
    "light_curve_sigma = torch.sqrt(torch.diag(hess_inv).abs()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimated light curve fluxes:\", light_curve_flux)\n",
    "print(\"Estimated light curve uncertainties:\", light_curve_sigma)\n",
    "plt.errorbar(times.numpy(), light_curve_flux, yerr=light_curve_sigma, fmt='o', label='Estimated flux')\n",
    "plt.plot(times.numpy(), true_LC, 'o', label='True flux')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('SN flux')\n",
    "plt.ylim(0,None)\n",
    "plt.title('Estimated SN flux over time (Joint Model)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832fdc9",
   "metadata": {},
   "source": [
    "Clearly this is much more stable than fitting each image individually. The faint times of the SN lightcurve are very hard to find in the data, but using the position from the bright times we can lock it in so that we have a good position at all times, once the position is determined it is possible to measure the flux even though it is faint!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac8dc68",
   "metadata": {},
   "source": [
    "## Analysis Improvement: Functional Light Curve\n",
    "\n",
    "We know the function for the light curve, it is a Gaussian in time (for this mock data at least), so we can encode that knowledge into our simulator by making the SN flux dependent on that function rather than a free parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2bba7",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "imgmodels = []\n",
    "for i in range(Nobs):\n",
    "    SNmodel = Gaussian(f\"SN{i}\", x0=-0.35, y0=-0.2, q=1.0, phi=0.0, sigma=0.05, flux=0.2) # we start from true parameters for demo simplicity\n",
    "    SNmodel.x0.to_dynamic() # \"unknown\" parameters\n",
    "    SNmodel.y0.to_dynamic()\n",
    "    SNmodel.flux.to_dynamic()\n",
    "    Galaxymodel = Gaussian(f\"Galaxy{i}\", x0=0.2, y0=0.2, q=0.6, phi=0.5, sigma=0.3, flux=1.0)\n",
    "    Galaxymodel.to_dynamic() # \"unknown\" parameters\n",
    "    imgmodel = Combined(f\"image{i}\", imgx, imgy, [SNmodel, Galaxymodel])\n",
    "    imgmodels.append(imgmodel)\n",
    "    if i > 0: # Shared parameters across images\n",
    "        SNmodel.x0 = imgmodels[0].models[0].x0\n",
    "        SNmodel.y0 = imgmodels[0].models[0].y0\n",
    "        Galaxymodel.x0 = imgmodels[0].models[1].x0\n",
    "        Galaxymodel.y0 = imgmodels[0].models[1].y0\n",
    "        Galaxymodel.q = imgmodels[0].models[1].q\n",
    "        Galaxymodel.phi = imgmodels[0].models[1].phi\n",
    "        Galaxymodel.sigma = imgmodels[0].models[1].sigma\n",
    "        Galaxymodel.flux = imgmodels[0].models[1].flux\n",
    "thirdmodel = Stack(\"thirdmodel\", imgmodels)\n",
    "likelihood3 = Likelihood(\"likelihood3\", thirdmodel, data, sigma_read=sigma_read, exp_time=exp_time)\n",
    "likelihood3.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurvemodel = Gaussian1D(\"lightcurvemodel\", t0=-3.0, sigma=2.5, peak_flux=0.25)\n",
    "lightcurvemodel.to_dynamic()\n",
    "for i in range(Nobs):\n",
    "    thirdmodel.models[i].models[0].flux = lambda p: p.lightcurvemodel.flux(p.eval_t)\n",
    "    thirdmodel.models[i].models[0].flux.link(lightcurvemodel)\n",
    "    thirdmodel.models[i].models[0].flux.eval_t = times[i].clone()\n",
    "likelihood3.graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268f6ca",
   "metadata": {},
   "source": [
    "Take a moment to appreciate the complexity of this model despite very little work on our part or alteration of our original model. For the supernovae, they all share a position but each flux is a function of a light curve model evaluated at different times. We fixed the sigma for the SN assuming we knew the PSF but we could just as easily set it to dynamic and now we would be fitting the PSF width alongside all the other parameters! The galaxy is more straightforward, since all parameters are held constant, but consider that we didn't need to modify our gaussian or likelihood code to enforce this, we did it by linking parameters, so we didn't need to rewrite our likelihood or gaussian models and could reuse them for other models/projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd783dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit light curve\n",
    "x0 = likelihood3.build_params_array()\n",
    "x0 += torch.randn_like(x0) * 0.05  # Add some noise to the initial guess since we cant start at the true values\n",
    "res = minimize(lambda x: -likelihood3(torch.tensor(x)).numpy(), x0, method='Nelder-Mead')\n",
    "fig, axarr = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(\"Fit Model and Residuals (Joint Functional Model)\")\n",
    "model_imgs = thirdmodel(torch.tensor(res.x))\n",
    "residuals = likelihood3.residuals(torch.tensor(res.x))[0]\n",
    "for i in range(Nobs):\n",
    "    print(thirdmodel.models[i].models[0].flux.eval_t)\n",
    "    axarr[0][i].imshow(model_imgs[i].detach().numpy(), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "    axarr[0][i].set_title(f\"t={times[i]:.2f}\")\n",
    "    axarr[0][i].axis(\"off\")\n",
    "    axarr[1][i].imshow(residuals[i].detach().numpy(), origin=\"lower\", vmin=-3, vmax=3)\n",
    "    axarr[1][i].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# extract light curve\n",
    "likelihood3.fill_dynamic_values(torch.tensor(res.x))\n",
    "likelihood3.to_static(False)\n",
    "light_curve_flux = []\n",
    "light_curve_sigma = []\n",
    "for model in thirdmodel.models:\n",
    "    light_curve_flux.append(model.models[0].flux.value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimated light curve fluxes:\", light_curve_flux)\n",
    "plt.plot(times.numpy(), light_curve_flux, 'o', label='Estimated flux', markersize = 6)\n",
    "plt.plot(times.numpy(), true_LC, 'o', label='True flux')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('SN flux')\n",
    "plt.ylim(0,None)\n",
    "plt.title('Estimated SN flux over time (Joint Functional Model)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5ae80a",
   "metadata": {},
   "source": [
    "Now we do even better! Since we know the form of the light curve, that gives us extra constraining power. Instead of fitting 5 fluxes, we now fit the three `t0`, `sigma`, `peak_flux` parameters and so we get even better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8225e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurvemodel.to_dynamic()\n",
    "hess = hessian(likelihood3, likelihood3.build_params_array(), strict=True)\n",
    "hess_inv = torch.linalg.inv(hess)  # Invert the Hessian to get the covariance matrix\n",
    "light_curve_sigma = torch.sqrt(torch.diag(hess_inv).abs()).numpy()\n",
    "print(f\"Light Curve t0: {lightcurvemodel.t0.value.item():.2f} ± {light_curve_sigma[0]:.2f} vs {SN_lightcurve.t0.value.item():.2f} (true)\")\n",
    "print(f\"Light Curve sigma: {lightcurvemodel.sigma.value.item():.2f} ± {light_curve_sigma[1]:.2f} vs {SN_lightcurve.sigma.value.item():.2f} (true)\")\n",
    "print(f\"Light Curve peak flux: {lightcurvemodel.peak_flux.value.item():.2f} ± {light_curve_sigma[2]:.2f} vs {SN_lightcurve.peak_flux.value.item():.2f} (true)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8e375",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03927174",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
