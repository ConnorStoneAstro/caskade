{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b44e33",
   "metadata": {},
   "source": [
    "# Example: SN Light-Curve\n",
    "\n",
    "Here we will work through an example to show the power of `caskade` in simplifying the process of developing an analysis routine. We will use a mock highly simplified supernova light curve fitting problem as our example. In this we will start with a simple analysis where we fit each light curve image separately, then we will use `caskade`'s parameter linking to join the data into a single likelihood, finally we will use function pointers to fit a light curve model rather than individual brightnesses. At each stage we will se how `caskade` makes it easy to build on past work and how it keeps track of all the parameters for us. The power of `caskade` is that it makes the development process easier so we don't need to rewrite code or redo work as our model of the problem grows in complexity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caskade as ck\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd.functional import hessian\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib import colormaps\n",
    "from IPython.display import HTML\n",
    "from scipy.optimize import minimize\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357e549",
   "metadata": {},
   "source": [
    "Below we define our Gaussian and Combined modules like before. Expand to see the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d15e01",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "class Gaussian(ck.Module):\n",
    "    def __init__(self, name, x0=None, y0=None, q=None, phi=None, sigma=None, flux=None):\n",
    "        super().__init__(name)\n",
    "        self.x0 = ck.Param(\"x0\", x0)  # position\n",
    "        self.y0 = ck.Param(\"y0\", y0)\n",
    "        self.q = ck.Param(\"q\", q)  # axis ratio\n",
    "        self.phi = ck.Param(\"phi\", phi)  # orientation\n",
    "        self.sigma = ck.Param(\"sigma\", sigma)  # width\n",
    "        self.flux = ck.Param(\"flux\", flux)  # total light\n",
    "\n",
    "    @ck.forward\n",
    "    def _r(self, x, y, x0=None, y0=None, q=None, phi=None):\n",
    "        x, y = x - x0, y - y0\n",
    "        s, c = torch.sin(phi), torch.cos(phi)\n",
    "        x, y = c * x - s * y, s * x + c * y\n",
    "        return (x**2 + (y * q) ** 2).sqrt()\n",
    "\n",
    "    @ck.forward\n",
    "    def brightness(self, x, y, sigma=None, flux=None):\n",
    "        return flux * (-self._r(x, y) ** 2 / sigma**2).exp() / (2 * torch.pi * sigma**2).sqrt()\n",
    "\n",
    "\n",
    "class Gaussian1D(ck.Module):\n",
    "    def __init__(self, name, t0=None, sigma=None, peak_flux=None):\n",
    "        super().__init__(name)\n",
    "        self.t0 = ck.Param(\"t0\", t0)  # position\n",
    "        self.sigma = ck.Param(\"sigma\", sigma)  # width\n",
    "        self.peak_flux = ck.Param(\"peak_flux\", peak_flux)  # intensity\n",
    "\n",
    "    @ck.forward\n",
    "    def flux(self, t, peak_flux, t0, sigma):\n",
    "        return peak_flux * (-(((t + t0) / sigma) ** 2)).exp()\n",
    "\n",
    "\n",
    "class Combined(ck.Module):\n",
    "    def __init__(self, name, x, y, models):\n",
    "        super().__init__(name)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.models = models\n",
    "\n",
    "    @ck.forward\n",
    "    def __call__(self):\n",
    "        return sum(model.brightness(self.x, self.y) for model in self.models)\n",
    "\n",
    "\n",
    "class Noiser(ck.Module):\n",
    "    def __init__(self, name, model, read_noise=0.1, exp_time=100):\n",
    "        super().__init__(name)\n",
    "        self.model = model\n",
    "        self.read_noise = read_noise\n",
    "        self.exp_time = exp_time\n",
    "\n",
    "    @ck.forward\n",
    "    def __call__(self):\n",
    "        img = self.model()\n",
    "        read_noise = torch.randn_like(img) * self.read_noise\n",
    "        poisson_noise = torch.randn_like(img) * (img * self.exp_time).sqrt() / self.exp_time\n",
    "        return img + read_noise + poisson_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a511ca",
   "metadata": {},
   "source": [
    "## Making the mock data\n",
    "\n",
    "This has to be done first since that is what we will analyze, however you should skip this section and come back to it after you've read the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nobs = 5\n",
    "imgsize = 50\n",
    "sigma_read = 0.1\n",
    "exp_time = 25\n",
    "imgx, imgy = torch.meshgrid(\n",
    "    torch.linspace(-1, 1, imgsize), torch.linspace(-1, 1, imgsize), indexing=\"ij\"\n",
    ")\n",
    "SN = Gaussian(\"SN\", x0=-0.35, y0=-0.2, q=1.0, phi=0.0, sigma=0.05)\n",
    "SN_lightcurve = Gaussian1D(\"lightcurve\", t0=-3.0, sigma=2.0, peak_flux=0.25)\n",
    "time = ck.Param(\"time\")\n",
    "SN.flux = lambda p: p.lightcurve.flux(p.time.value)\n",
    "SN.flux.link((SN_lightcurve, time))\n",
    "Galaxy = Gaussian(\"Galaxy\", x0=0.2, y0=0.2, q=0.6, phi=0.5, sigma=0.3, flux=1.0)\n",
    "sim = Combined(\"sim\", imgx, imgy, [SN, Galaxy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91da26b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "B = 64\n",
    "fig, ax = plt.subplots()\n",
    "times = torch.linspace(0, 6, B)\n",
    "img = ax.imshow(sim([times[0]]), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "ax.set_title(\"Brightness at time 0\")\n",
    "\n",
    "\n",
    "def update(i):\n",
    "    img.set_data(sim([times[i]]).detach().numpy())\n",
    "    ax.set_title(f\"Brightness at time {times[i]:.2f}\")\n",
    "    return img\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=B, interval=60)\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Or display the animation inline\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a7a3c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "times = torch.linspace(0, 6, Nobs)\n",
    "data = torch.zeros((Nobs, imgsize, imgsize))\n",
    "true_LC = SN_lightcurve.flux(times).detach().numpy()\n",
    "torch.manual_seed(1123)  # For reproducibility\n",
    "noise_sim = Noiser(\"noise_sim\", sim, read_noise=sigma_read, exp_time=exp_time)\n",
    "fig, axarr = plt.subplots(1, 5, figsize=(15, 3))\n",
    "fig.suptitle(\"Mock Observations\")\n",
    "for i, t in enumerate(times):\n",
    "    data[i] = noise_sim([t])\n",
    "    axarr[i].imshow(data[i].detach().numpy(), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "    axarr[i].set_title(f\"t={t:.2f}\")\n",
    "    axarr[i].set_xlabel(\"X\")\n",
    "    axarr[i].set_ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5215be",
   "metadata": {},
   "source": [
    "## Analysis starting point: Model each image individually\n",
    "\n",
    "Let's imagine we are new to this problem and just starting out. We will make things simple and just analyze each image individually to construct our light curve. We are going to assume throughout that you know things like the read noise of your detector and the exposure time (which we are using as a basic noise model).\n",
    "\n",
    "We will perform a straightforward likelihood analysis, thus our main goal will be to construct a likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfaf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood(ck.Module):\n",
    "    def __init__(self, name, model, data, sigma_read=0.05, exp_time=25):\n",
    "        super().__init__(name)\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.sigma_read = sigma_read\n",
    "        self.exp_time = exp_time\n",
    "\n",
    "    @ck.forward\n",
    "    def residuals(self):\n",
    "        model_output = self.model()\n",
    "        variance = self.sigma_read**2 + model_output / self.exp_time\n",
    "        sigma = variance.sqrt()\n",
    "        residuals = (self.data - model_output) / sigma\n",
    "        return residuals, sigma\n",
    "\n",
    "    @ck.forward\n",
    "    def __call__(self):  # log likelihood\n",
    "        residuals, sigma = self.residuals()\n",
    "        return -0.5 * (residuals**2).sum() - sigma.log().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "SNmodel = Gaussian(\"SN\", x0=-0.35, y0=-0.2, q=1.0, phi=0.0, sigma=0.05, flux=0.2)\n",
    "SNmodel.x0.to_dynamic()  # \"unknown\" parameters\n",
    "SNmodel.y0.to_dynamic()\n",
    "SNmodel.flux.to_dynamic()\n",
    "Galaxymodel = Gaussian(\"Galaxy\", x0=0.2, y0=0.2, q=0.6, phi=0.5, sigma=0.3, flux=1.0)\n",
    "Galaxymodel.to_dynamic()  # \"unknown\" parameters\n",
    "firstmodel = Combined(\"firstmodel\", imgx, imgy, [SNmodel, Galaxymodel])\n",
    "likelihood = Likelihood(\"likelihood\", firstmodel, data[0], sigma_read=sigma_read, exp_time=exp_time)\n",
    "likelihood.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_curve_flux = []\n",
    "light_curve_sigma = []\n",
    "model_images = []\n",
    "model_residuals = []\n",
    "for i in range(Nobs):\n",
    "    likelihood.data = data[i]  # Update the data for each observation\n",
    "\n",
    "    # Fit the model\n",
    "    x0 = likelihood.get_values(\"array\")  # default is \"array\", we just added it for show\n",
    "    x0 += (\n",
    "        torch.randn_like(x0) * x0 * 0.05\n",
    "    )  # Add some noise to the initial guess since we cant start at the true values\n",
    "    res = minimize(lambda x: -likelihood(torch.tensor(x)).numpy(), x0, method=\"Nelder-Mead\")\n",
    "    light_curve_flux.append(res.x[2])\n",
    "\n",
    "    # Get uncertainty using inverse Hessian\n",
    "    hess = -hessian(likelihood, torch.tensor(res.x), strict=True)\n",
    "    hess_inv = torch.linalg.inv(hess)\n",
    "    light_curve_sigma.append(hess_inv[2, 2].abs().sqrt().item())\n",
    "\n",
    "    # Store model images and residuals\n",
    "    model_images.append(firstmodel(torch.tensor(res.x)).detach().numpy())\n",
    "    model_residuals.append(likelihood.residuals(torch.tensor(res.x))[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f12c9",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(\"Fit Model and Residuals\")\n",
    "for i in range(Nobs):\n",
    "    axarr[0][i].imshow(model_images[i], origin=\"lower\", vmin=0, vmax=1.5)\n",
    "    axarr[0][i].set_title(f\"t={times[i]:.2f}\")\n",
    "    axarr[0][i].axis(\"off\")\n",
    "    axarr[1][i].imshow(model_residuals[i], origin=\"lower\", vmin=-3, vmax=3)\n",
    "    axarr[1][i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4555b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.errorbar(\n",
    "    times.numpy(), light_curve_flux, yerr=light_curve_sigma, fmt=\"o\", label=\"Estimated flux\"\n",
    ")\n",
    "plt.plot(times.numpy(), true_LC, \"o\", label=\"True flux\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"SN flux\")\n",
    "plt.ylim(0, None)\n",
    "plt.title(\"Estimated SN flux over time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45fa18d",
   "metadata": {},
   "source": [
    "This is our first go at measuring the light curve. It mostly looks like what we should expect, the bright points are fit well but the faint ones fail and we get no meaningful flux estimate from them. For the very faint SN images, it is hard to see in the noise where the SN even is, let alone determine its flux. So next lets see if we can add some complexity to our model and get better results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b35d2",
   "metadata": {},
   "source": [
    "## Analysis Improvement: Joint modelling\n",
    "\n",
    "We don't need to analyze each image individually, we have some knowledge of how these SN should look in our data. For example, the position of the SN and galaxy should be constant with time, further, the galaxy should really be fixed over time, the only thing that changes is the SN flux, so lets encode that in our analysis.\n",
    "\n",
    "`caksade` lets us fix parameters to match each other, so we will make a model for each image then link the parameters accordingly to the first image model. This way our parameter vector will only include what's needed to model the full set of images. We also create a wrapper module to stack the results from all the models so it can easily be passed to the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One galaxy model since it does not change across images\n",
    "Galaxymodel = Gaussian(f\"Galaxy{i}\", x0=0.2, y0=0.2, q=0.6, phi=0.5, sigma=0.3, flux=1.0)\n",
    "Galaxymodel.to_dynamic()  # \"unknown\" parameters\n",
    "\n",
    "imgmodels = []\n",
    "for i in range(Nobs):\n",
    "    SNmodel = Gaussian(f\"SN{i}\", x0=-0.35, y0=-0.2, q=1.0, phi=0.0, sigma=0.05, flux=0.2)\n",
    "    SNmodel.x0.to_dynamic()  # \"unknown\" parameters\n",
    "    SNmodel.y0.to_dynamic()\n",
    "    SNmodel.flux.to_dynamic()\n",
    "    imgmodel = Combined(f\"image{i}\", imgx, imgy, [SNmodel, Galaxymodel])\n",
    "    imgmodels.append(imgmodel)\n",
    "    if i > 0:  # SN position doesnt change across images\n",
    "        SNmodel.x0 = imgmodels[0].models[0].x0\n",
    "        SNmodel.y0 = imgmodels[0].models[0].y0\n",
    "\n",
    "\n",
    "class Stack(ck.Module):\n",
    "    def __init__(self, name, models):\n",
    "        super().__init__(name)\n",
    "        self.models = models\n",
    "\n",
    "    @ck.forward\n",
    "    def __call__(self):\n",
    "        return torch.stack([model() for model in self.models], dim=0)\n",
    "\n",
    "\n",
    "secondmodel = Stack(\"secondmodel\", imgmodels)\n",
    "likelihood2 = Likelihood(\"likelihood2\", secondmodel, data, sigma_read=sigma_read, exp_time=exp_time)\n",
    "likelihood2.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit light curve\n",
    "x0 = likelihood2.get_values()\n",
    "x0 += (\n",
    "    torch.randn_like(x0) * x0 * 0.05\n",
    ")  # Add some noise to the initial guess since we cant start at the true values\n",
    "res = minimize(lambda x: -likelihood2(torch.tensor(x)).numpy(), x0, method=\"Nelder-Mead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a4bf5",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(\"Fit Model and Residuals (Joint Model)\")\n",
    "model_imgs = secondmodel(torch.tensor(res.x))\n",
    "residuals = likelihood2.residuals(torch.tensor(res.x))[0]\n",
    "for i in range(Nobs):\n",
    "    axarr[0][i].imshow(model_imgs[i].detach().numpy(), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "    axarr[0][i].set_title(f\"t={times[i]:.2f}\")\n",
    "    axarr[0][i].axis(\"off\")\n",
    "    axarr[1][i].imshow(residuals[i].detach().numpy(), origin=\"lower\", vmin=-3, vmax=3)\n",
    "    axarr[1][i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a10138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract light curve\n",
    "likelihood2.set_values(torch.tensor(res.x))\n",
    "likelihood2.to_static(children_only=False)\n",
    "light_curve_flux = []\n",
    "light_curve_sigma = []\n",
    "for model in secondmodel.models:\n",
    "    light_curve_flux.append(model.models[0].flux.value.item())\n",
    "    model.models[0].flux.to_dynamic()\n",
    "\n",
    "# Compute uncertainty using inverse Hessian\n",
    "hess = -hessian(likelihood2, likelihood2.get_values(), strict=True)\n",
    "hess_inv = torch.linalg.inv(hess)  # Invert the Hessian to get the covariance matrix\n",
    "light_curve_sigma = torch.sqrt(torch.diag(hess_inv)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa5bf2",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Estimated light curve fluxes:\", light_curve_flux)\n",
    "print(\"Estimated light curve uncertainties:\", light_curve_sigma)\n",
    "plt.errorbar(\n",
    "    times.numpy(), light_curve_flux, yerr=light_curve_sigma, fmt=\"o\", label=\"Estimated flux\"\n",
    ")\n",
    "plt.plot(times.numpy(), true_LC, \"o\", label=\"True flux\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"SN flux\")\n",
    "plt.ylim(0, None)\n",
    "plt.title(\"Estimated SN flux over time (Joint Model)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832fdc9",
   "metadata": {},
   "source": [
    "Clearly this is much more stable than fitting each image individually. The faint times of the SN lightcurve are very hard to find in the data, but using the position from the bright times we can lock it in so that we have a good position at all times, once the position is determined it is possible to measure the flux even though it is faint!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac8dc68",
   "metadata": {},
   "source": [
    "## Analysis Improvement: Functional Light Curve\n",
    "\n",
    "We know the function for the light curve, it is a Gaussian in time (for this mock data at least), so we can encode that knowledge into our simulator by making the SN flux dependent on that function rather than a free parameter. What's incredible is that we can simply reuse the previous model and tack on a new function of time to control the fluxes of the SN, no need to modify any of the previous code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff152b92",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# re-set appropriate parameters to dynamic again\n",
    "secondmodel.models[0].models[1].to_dynamic()  # make galaxy model dynamic\n",
    "secondmodel.models[0].models[0].x0.to_dynamic()  # make SN position dynamic\n",
    "secondmodel.models[0].models[0].y0.to_dynamic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add light curve model to control the fluxes\n",
    "lightcurvemodel = Gaussian1D(\"lightcurvemodel\", t0=-3.0, sigma=2.5, peak_flux=0.25)\n",
    "lightcurvemodel.to_dynamic()\n",
    "for i in range(Nobs):\n",
    "    secondmodel.models[i].models[0].flux = lambda p: p.lightcurvemodel.flux(t=p.eval_t)\n",
    "    secondmodel.models[i].models[0].flux.link(lightcurvemodel)\n",
    "    secondmodel.models[i].models[0].flux.eval_t = times[i].clone()\n",
    "likelihood2.graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268f6ca",
   "metadata": {},
   "source": [
    "Take a moment to appreciate the complexity of this model despite very little work on our part or alteration of our original gaussian light model. For the supernovae, they all share a position but each flux is a function of a light curve model evaluated at different times. We fixed the sigma for the SN assuming we knew the PSF but we could just as easily set it to dynamic and now we would be fitting the PSF width alongside all the other parameters! The galaxy is more straightforward, since all parameters are held constant, but consider that we didn't need to modify our gaussian or likelihood code to enforce this, we did it by linking parameters, so we didn't need to rewrite our likelihood or gaussian models and could reuse them for other models/projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd783dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit light curve\n",
    "x0 = likelihood2.get_values()\n",
    "x0 += (\n",
    "    torch.randn_like(x0) * x0 * 0.05\n",
    ")  # Add some noise to the initial guess since we cant start at the true values\n",
    "res = minimize(lambda x: -likelihood2(torch.tensor(x)).numpy(), x0, method=\"Nelder-Mead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4395a23",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(\"Fit Model and Residuals (Joint Functional Model)\")\n",
    "model_imgs = secondmodel(torch.tensor(res.x))\n",
    "residuals = likelihood2.residuals(torch.tensor(res.x))[0]\n",
    "for i in range(Nobs):\n",
    "    axarr[0][i].imshow(model_imgs[i].detach().numpy(), origin=\"lower\", vmin=0, vmax=1.5)\n",
    "    axarr[0][i].set_title(f\"t={times[i]:.2f}\")\n",
    "    axarr[0][i].axis(\"off\")\n",
    "    axarr[1][i].imshow(residuals[i].detach().numpy(), origin=\"lower\", vmin=-3, vmax=3)\n",
    "    axarr[1][i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15485c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract light curve\n",
    "likelihood2.set_values(torch.tensor(res.x))\n",
    "light_curve_flux = []\n",
    "light_curve_sigma = []\n",
    "for model in secondmodel.models:\n",
    "    light_curve_flux.append(model.models[0].flux.value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b0526",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Estimated light curve fluxes:\", light_curve_flux)\n",
    "plt.plot(times.numpy(), light_curve_flux, \"o\", label=\"Estimated flux\", markersize=6)\n",
    "plt.plot(times.numpy(), true_LC, \"o\", label=\"True flux\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"SN flux\")\n",
    "plt.ylim(0, None)\n",
    "plt.title(\"Estimated SN flux over time (Joint Functional Model)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5ae80a",
   "metadata": {},
   "source": [
    "Now we do even better! Since we know the form of the light curve, that gives us extra constraining power. Instead of fitting 5 fluxes, we now fit the three `t0`, `sigma`, `peak_flux` parameters and so we get even better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8225e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood2.to_static(False)\n",
    "lightcurvemodel.to_dynamic()\n",
    "fit_vals = likelihood2.get_values()\n",
    "hess = -hessian(likelihood2, fit_vals, strict=True)\n",
    "hess_inv = torch.linalg.inv(hess)  # Invert the Hessian to get the covariance matrix\n",
    "light_curve_sigma = torch.sqrt(torch.diag(hess_inv).abs()).numpy()\n",
    "print(\n",
    "    f\"Light Curve t0: {fit_vals[0].item():.2f} ± {light_curve_sigma[0]:.2f} vs {SN_lightcurve.t0.value.item():.2f} (true)\"\n",
    ")\n",
    "print(\n",
    "    f\"Light Curve sigma: {fit_vals[1].item():.2f} ± {light_curve_sigma[1]:.2f} vs {SN_lightcurve.sigma.value.item():.2f} (true)\"\n",
    ")\n",
    "print(\n",
    "    f\"Light Curve peak flux: {fit_vals[2].item():.3f} ± {light_curve_sigma[2]:.3f} vs {SN_lightcurve.peak_flux.value.item():.3f} (true)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119a4df",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.axvline(SN_lightcurve.sigma.value.item(), color=\"r\", linestyle=\"--\", label=\"True values\")\n",
    "ax.axhline(SN_lightcurve.peak_flux.value.item(), color=\"r\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Sigma\")\n",
    "ax.set_ylabel(\"Peak Flux\")\n",
    "lambda_, v = np.linalg.eig(hess_inv[1:, 1:])\n",
    "lambda_ = np.sqrt(lambda_)\n",
    "angle = np.rad2deg(np.arctan2(v[1, 0], v[0, 0]))\n",
    "for k in [1, 2]:\n",
    "    ellipse = Ellipse(\n",
    "        xy=(fit_vals[1].item(), fit_vals[2].item()),\n",
    "        width=lambda_[0] * k * 2,\n",
    "        height=lambda_[1] * k * 2,\n",
    "        angle=angle,\n",
    "        edgecolor=\"black\",\n",
    "        facecolor=\"grey\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    ax.add_artist(ellipse)\n",
    "plt.plot([], [], c=\"k\", label=\"Likelihood Contours\")\n",
    "ax.set_xlim(fit_vals[1].item() - lambda_[0] * 3, fit_vals[1].item() + lambda_[0] * 3)\n",
    "ax.set_ylim(fit_vals[2].item() - lambda_[1] * 3, fit_vals[2].item() + lambda_[1] * 3)\n",
    "ax.set_title(\"Light Curve Parameter Uncertainty (Hessian)\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2d7d1",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# re-set appropriate parameters to dynamic again\n",
    "secondmodel.models[0].models[1].to_dynamic()  # make galaxy model dynamic\n",
    "secondmodel.models[0].models[0].x0.to_dynamic()  # make SN position dynamic\n",
    "secondmodel.models[0].models[0].y0.to_dynamic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79618d5c",
   "metadata": {},
   "source": [
    "### Sampling vs Optimizing\n",
    "\n",
    "`caskade` turns our simulator and likelihood into simple functions of a 1D vector, we can use other packages besides `scipy.optimize.minimize` to analyze our data now. Here we try the `emcee` package for MCMC sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsim = torch.vmap(likelihood2)\n",
    "\n",
    "\n",
    "# Log-likelihood function\n",
    "def density(x):\n",
    "    return vsim(torch.as_tensor(x, dtype=torch.float32)).numpy()\n",
    "\n",
    "\n",
    "x0 = likelihood2.get_values()\n",
    "nwalkers = 32\n",
    "ndim = len(x0)\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, density, vectorize=True)\n",
    "\n",
    "x0 = x0 * (1 + 0.1 * torch.randn(nwalkers, ndim, dtype=torch.float32))\n",
    "print(\"burn-in\")\n",
    "state = sampler.run_mcmc(x0, 100, skip_initial_state_check=True)  # burn-in\n",
    "sampler.reset()\n",
    "print(\"production\")\n",
    "state = sampler.run_mcmc(state, 1000)  # production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc7f6a",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "SN_lightcurve.to_dynamic()\n",
    "Galaxy.to_dynamic()\n",
    "true_values = (\n",
    "    [SN.x0.value.item(), SN.y0.value.item()]\n",
    "    + list(SN_lightcurve.get_values().numpy())\n",
    "    + list(Galaxy.get_values().numpy())\n",
    ")\n",
    "chain_mh = sampler.get_chain(flat=True)\n",
    "fig, axarr = plt.subplots(ndim, ndim, figsize=(12, 12))\n",
    "plt.subplots_adjust(hspace=0.0, wspace=0.0)\n",
    "labels = list(p.name for p in likelihood2.dynamic_params)\n",
    "labels[0] = \"SN x0\"\n",
    "labels[1] = \"SN y0\"\n",
    "labels[5] = \"Gal x0\"\n",
    "labels[6] = \"Gal y0\"\n",
    "for i in range(ndim):\n",
    "    for j in range(ndim):\n",
    "        if j > i:\n",
    "            axarr[i, j].axis(\"off\")\n",
    "            continue\n",
    "        axarr[i, j].axvline(true_values[j], color=\"r\", label=\"True value\", linewidth=0.5)\n",
    "        axarr[i, j].set_xlim(chain_mh[:, j].min(), chain_mh[:, j].max())\n",
    "        if i == j:\n",
    "            axarr[i, j].hist(chain_mh[:, i], bins=30, density=True)\n",
    "        else:\n",
    "            axarr[i, j].scatter(chain_mh[:, j][::25], chain_mh[:, i][::25], s=1, alpha=0.5)\n",
    "            axarr[i, j].axhline(true_values[i], color=\"r\", label=\"True value\", linewidth=0.5)\n",
    "            axarr[i, j].set_ylim(chain_mh[:, i].min(), chain_mh[:, i].max())\n",
    "\n",
    "        if j == 0:\n",
    "            axarr[i, j].set_ylabel(f\"{labels[i]}\")\n",
    "        if i == ndim - 1:\n",
    "            axarr[i, j].set_xlabel(f\"{labels[j]}\")\n",
    "        axarr[i, j].set_xticks([])\n",
    "        axarr[i, j].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61875f",
   "metadata": {},
   "source": [
    "## End note\n",
    "\n",
    "Now we are at the end you might think to yourself \"wouldn't it have been easier to just write the final model directly rather than using caskade?\" And in a sense you are right. One could probably sit down and write this model out as a single class or a small series of functions. The problem is that science is an iterative process and you will likely not begin your project by simply sitting down and writing a complete model of every feature in your data. You will experiment, and break things, and increase complexity, and backtrack, and change goals, and so on as the project changes in scope and the objective becomes clearer. What `caskade` really accomplishes is letting you do all that iteration quickly, without re-writing each time, in a less error prone way, letting you see changes visually in the graph, and letting a project grow in scale naturally. `caskade` is built for the scientific development process, and those who use it don't turn back. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8e375",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03927174",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY312 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
